# LLM Playground

O **LLM Playground** √© um ambiente interativo para experimentar modelos de linguagem (LLMs) localmente, ajustando par√¢metros como **temperature**, **top-k**, **top-p** e **max length** para entender como eles influenciam o comportamento e a criatividade das respostas.  

Este projeto utiliza **Python**, **Hugging Face Transformers** e **Gradio** para criar uma interface simples.

---
## Interface do LLM Playground

Abaixo est√° uma pr√©via da interface da aplica√ß√£o em execu√ß√£o localmente:

![Interface do LLM Playground](assets/ui.png)

---
---

## üß† Modelo Utilizado

O **LLM Playground** foi configurado para usar um modelo open source hospedado no [Hugging Face](https://huggingface.co), podendo ser facilmente trocado por outro compat√≠vel com a biblioteca `transformers`.

### üîπ Modelo padr√£o
**Nome:** `mistralai/Mistral-7B-Instruct-v0.2`  
**Tipo:** Modelo de linguagem autoregressivo (causal)  
**Tamanho:** 7 bilh√µes de par√¢metros  
**Arquitetura:** Transformer Decoder (base GPT)  
**Licen√ßa:** Open Source (Apache 2.0)  
**Treinamento:** Supervised Fine-Tuning em dados de instru√ß√£o multil√≠ngues  
**Dom√≠nio:** Instru√ß√µes gerais, racioc√≠nio e conversa√ß√£o  

O **Mistral-7B-Instruct** foi escolhido por equilibrar:
- üß© **Desempenho**: excelente qualidade de resposta com baixo tempo de infer√™ncia;  
- ‚ö° **Efici√™ncia**: roda localmente em Apple Silicon (M1‚ÄìM4) via MPS;  
- üß† **Capacidade**: suporte a racioc√≠nio, explica√ß√µes e tarefas de texto complexas;  
- üí¨ **Ader√™ncia a instru√ß√µes**: responde bem a prompts no estilo ‚Äúinstruct‚Äù (similar ao GPT-3.5).

---

### üß∞ Alternativas compat√≠veis

Voc√™ pode modificar o modelo no arquivo `app.py` trocando a linha:

```python
MODEL_NAME = "mistralai/Mistral-7B-Instruct-v0.2"


## 1. Instala√ß√£o do Conda no macOS

Primeiro, instale o **Miniconda** (vers√£o leve do Conda).  
No terminal, execute:

```bash
/bin/bash -c "$(curl -fsSL https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh)"
```

Ap√≥s a instala√ß√£o, feche e reabra o terminal e valide:
```bash
conda --version
```

## 2. Cria√ß√£o do ambiente virtual

Crie um novo ambiente Conda chamado llm-playground com Python 3.10:
```bash
conda create -n llm-playground python=3.12
```

## 3. Ativando o ambiente
Para ativar o ambiente criado:
```bash
conda activate llm-playground
```

Para desativar, use:
```bash
conda deactivate
```

## 4. Instalar o PIP
Dentro do ambiente ativo, garanta que o `pip` est√° instalado:
```bash
conda install pip
```

Verifique a instala√ß√£o:
```bash
pip --version
```

## Instalar as bibliotecas necess√°rias
Com o ambiente ativo, instale as depend√™ncias do projeto:
```bash
pip install -r requirements.txt
```

Exemplo do arquivo `requirements.txt`
```txt
transformers==4.44.0
torch==2.3.1
gradio==4.39.0
accelerate==0.33.0
```

## 6. Habilitar suporte MPS no PyTorch (GPU do Apple Silicon)
No macOS, o PyTorch utiliza o Metal Performance Shaders (MPS) para acelerar os c√°lculos em GPU. Antes de rodar a aplica√ß√£o, exporte esta vari√°vel no terminal:
```bash
export PYTORCH_ENABLE_MPS_FALLBACK=1
```

## 7. Inicializar a aplica√ß√£o
Com tudo instalado, rode a aplica√ß√£o:
```bash
python app.py
```

Voc√™ ver√° algo como:
```csharp
Running on local URL:  http://0.0.0.0:7860
```

## 8. Acessar o LLM Playground
Abra o navegador e acesse:

üëâ http://localhost:7860

Voc√™ ver√° a interface do LLM Playground, onde poder√°:

- Inserir prompts de texto

- Ajustar os par√¢metros (temperature, top-k, top-p, max length)

- Visualizar as respostas geradas em tempo real

# Dicas de Uso
| Par√¢metro       | Fun√ß√£o                               | Efeito Pr√°tico                         |
| --------------- | ------------------------------------ | -------------------------------------- |
| **Temperature** | Controla aleatoriedade               | 0.3 ‚Üí objetiva / 1.2 ‚Üí criativa        |
| **Top-K**       | Limita n√∫mero de palavras candidatas | 20 ‚Üí previs√≠vel / 100 ‚Üí variado        |
| **Top-P**       | Define probabilidade acumulada       | 0.8 ‚Üí respostas seguras / 1.0 ‚Üí livres |
| **Max Length**  | Tamanho m√°ximo da resposta           | 64 ‚Üí conciso / 256 ‚Üí detalhado         |

# Estrutura do rojeto
```bash
llm-playground/
‚îú‚îÄ‚îÄ app.py                # C√≥digo principal da aplica√ß√£o
‚îú‚îÄ‚îÄ requirements.txt      # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md             # Este arquivo de documenta√ß√£o
```

# Problemas comuns
| Erro                               | Causa prov√°vel                 | Solu√ß√£o                                 |
| ---------------------------------- | ------------------------------ | --------------------------------------- |
| `torch not found`                  | PyTorch n√£o instalado          | Reinstale com `pip install torch`       |
| `MPS not available`                | Vers√£o do macOS/PyTorch antiga | Atualize o PyTorch e macOS              |
| `RuntimeError: CUDA not available` | Macs n√£o possuem CUDA          | Use `device_map="mps"` no c√≥digo        |
| Interface n√£o abre                 | Porta 7860 em uso              | Rode `python app.py --server_port 7870` |

# Licen√ßa
Este projeto √© distribu√≠do sob a licen√ßa MIT.
Sinta-se livre para modificar e aprimorar conforme suas necessidades.